{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "18819 project - cv approach.ipynb",
      "provenance": [],
      "collapsed_sections": []
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "WuJCsusOG64P"
      },
      "source": [
        "Imports"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "qIRZx806G5E7"
      },
      "source": [
        "from keras.preprocessing.image import ImageDataGenerator\n",
        "import cv2\n",
        "import numpy as np\n",
        "from google.colab.patches import cv2_imshow\n",
        "from matplotlib import pyplot as plt\n",
        "import multiprocessing\n",
        "import scipy.ndimage\n",
        "import skimage\n",
        "import sklearn.cluster\n",
        "import scipy.spatial.distance\n",
        "import os, time\n",
        "import matplotlib.pyplot as plt\n",
        "import random\n",
        "from skimage import io\n",
        "from keras.datasets import mnist "
      ],
      "execution_count": 1,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "KWVr-9kJHHmo"
      },
      "source": [
        "Pre-processing [for Mnist dataset](https://machinelearningmastery.com/how-to-normalize-center-and-standardize-images-with-the-imagedatagenerator-in-keras/)"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 421
        },
        "id": "LH0huhhmHHCW",
        "outputId": "93ff2126-33d2-4bba-83c1-5e044e75f7d8"
      },
      "source": [
        "(X_train, y_train), (X_test, y_test) = mnist.load_data()\n",
        "\n",
        "datagen = ImageDataGenerator(featurewise_center=True,\n",
        "                             featurewise_std_normalization=True)\n",
        "img = datagen.standardize(X_train[1])\n",
        "operatedImage = np.float32(img) / 255\n",
        "plt.imshow(operatedImage,cmap='gray')"
      ],
      "execution_count": 2,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Downloading data from https://storage.googleapis.com/tensorflow/tf-keras-datasets/mnist.npz\n",
            "11493376/11490434 [==============================] - 0s 0us/step\n",
            "11501568/11490434 [==============================] - 0s 0us/step\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.7/dist-packages/keras_preprocessing/image/image_data_generator.py:720: UserWarning: This ImageDataGenerator specifies `featurewise_center`, but it hasn't been fit on any training data. Fit it first by calling `.fit(numpy_data)`.\n",
            "  warnings.warn('This ImageDataGenerator specifies '\n",
            "/usr/local/lib/python3.7/dist-packages/keras_preprocessing/image/image_data_generator.py:728: UserWarning: This ImageDataGenerator specifies `featurewise_std_normalization`, but it hasn't been fit on any training data. Fit it first by calling `.fit(numpy_data)`.\n",
            "  warnings.warn('This ImageDataGenerator specifies '\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<matplotlib.image.AxesImage at 0x7f8308f20210>"
            ]
          },
          "metadata": {},
          "execution_count": 2
        },
        {
          "output_type": "display_data",
          "data": {
            "image/png": "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\n",
            "text/plain": [
              "<Figure size 432x288 with 1 Axes>"
            ]
          },
          "metadata": {
            "needs_background": "light"
          }
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ttituC1-Iz7y"
      },
      "source": [
        "# Feature extraction"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "N6PULI54X309"
      },
      "source": [
        "Harris corner detector"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "VbndKBQvIyty"
      },
      "source": [
        "def get_harris_points(operatedImage):\n",
        "  dest = cv2.cornerHarris(operatedImage, 2, 3, 0.04)\n",
        "  dest = cv2.dilate(dest, None)\n",
        "  HarrisImage = np.copy(operatedImage)\n",
        "  HarrisImage = np.stack((HarrisImage, HarrisImage, HarrisImage), axis=-1)\n",
        "  HarrisImage[abs(dest) > 0.05 * dest.max()] = [255,0,0]\n",
        "  harris_points = list(np.where(abs(dest) > 0.05 * dest.max()))\n",
        "  return harris_points"
      ],
      "execution_count": 3,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Xa8-g74zX6j1"
      },
      "source": [
        "filter responses"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "OEvDYdqoX9tR"
      },
      "source": [
        "def display_filter_responses(response_maps):\n",
        "    '''\n",
        "    Visualizes the filter response maps.\n",
        "\n",
        "    [input]\n",
        "    * response_maps: a numpy.ndarray of shape (H, W, 3F)\n",
        "    '''\n",
        "\n",
        "    fig = plt.figure(1)\n",
        "\n",
        "    for i in range(20):\n",
        "        plt.subplot(5, 4, i+1)\n",
        "        resp = response_maps[:, :, i]\n",
        "        resp_min = resp.min(axis=(0, 1), keepdims=True)\n",
        "        resp_max = resp.max(axis=(0, 1), keepdims=True)\n",
        "        resp = (resp-resp_min)/(resp_max-resp_min)\n",
        "        plt.imshow(resp, cmap = 'gray')\n",
        "        plt.axis(\"off\")\n",
        "\n",
        "    plt.subplots_adjust(left=0.05,right=0.95,top=0.95,bottom=0.05,wspace=0.05,hspace=0.05)\n",
        "    plt.show()"
      ],
      "execution_count": 4,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "EihiTvqWCxdc"
      },
      "source": [
        "Applying different filers on images for edge calculation"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "2VlrDsrTXbP5"
      },
      "source": [
        "def extract_filter_responses(image):\n",
        "    '''\n",
        "    Extracts the filter responses for the given image.\n",
        "\n",
        "    [input]\n",
        "    * image: numpy.ndarray of shape (H, W) \n",
        "\n",
        "    [output]\n",
        "    * filter_responses: numpy.ndarray of shape (H, W, F)\n",
        "    '''\n",
        "\n",
        "    image = image.astype('float')\n",
        "    image[image<0.5] = 0\n",
        "    filter_responses = []\n",
        "    \n",
        "    for scale in [1,2,4,8,8*np.sqrt(2)]:\n",
        "        #(1) Gaussian, (2) Laplacian of Gaussian, (3) derivative of Gaussian in the  ð‘¥  direction, and (4) derivative of Gaussian in the  ð‘¦  direction.\n",
        "        r = scipy.ndimage.gaussian_filter(image,scale)\n",
        "        gaussian = np.dstack([r])\n",
        "        \n",
        "        r = scipy.ndimage.gaussian_laplace(image,scale)\n",
        "        laplace = np.dstack([r])\n",
        "        \n",
        "        r = scipy.ndimage.filters.gaussian_filter(image,(scale,scale),(1,0))\n",
        "        y_dir = np.dstack([r])\n",
        "\n",
        "        r = scipy.ndimage.filters.gaussian_filter(image,(scale,scale),(0,1))\n",
        "        x_dir = np.dstack([r])\n",
        "        \n",
        "        if len(filter_responses) != 0:\n",
        "            filter_responses = np.dstack([filter_responses, gaussian,laplace,x_dir,y_dir])\n",
        "        else:\n",
        "            filter_responses = np.dstack([gaussian,laplace,x_dir,y_dir])\n",
        "    return filter_responses "
      ],
      "execution_count": 7,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "KVk3iNPfC3z5"
      },
      "source": [
        "Compare the image with filter responses and detect the common edge points"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "NcJZlwm4YKU9"
      },
      "source": [
        "def compute_dictionary_one_image(args):\n",
        "    '''\n",
        "    Extracts samples of the dictionary entries from an image. Use the the \n",
        "    harris corner detector implmented from previous question to extract \n",
        "    the point of interests. This should be a function run by a subprocess.\n",
        "\n",
        "    [input]\n",
        "    * i: index of training image\n",
        "    * image_path: image\n",
        "\n",
        "    [saved]\n",
        "    * sampled_response: numpy.ndarray of shape (alpha, 3F)\n",
        "    '''\n",
        "    i, image = args\n",
        "    if not os.path.isdir('tmp'):\n",
        "        os.mkdir('tmp')\n",
        "\n",
        "    f_name = 'tmp/%05d.npy' % i\n",
        "\n",
        "    harris_points = get_harris_points(image)\n",
        "    filter_responses = extract_filter_responses(image)\n",
        "    sampled_responses = np.zeros(( len(harris_points[0]),filter_responses.shape[2] ))\n",
        "\n",
        "    for i in range(len(harris_points[0])):\n",
        "        y,x = harris_points[0][i], harris_points[1][i]\n",
        "        for n in range(filter_responses.shape[2]):\n",
        "            sampled_responses[i,n] = filter_responses[y,x,n]\n",
        "    np.save(f_name,sampled_responses)"
      ],
      "execution_count": 8,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "AKt5Wrl0BQEw"
      },
      "source": [
        "---\n",
        "\n",
        "Training dataset processing\n",
        "\n",
        "\n",
        "---\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "pV3VmRHE75VO"
      },
      "source": [
        "def compute_dictionary(num_workers=2):\n",
        "    '''\n",
        "    Creates the dictionary of visual words by clustering using k-means.\n",
        "\n",
        "    [input]\n",
        "    * num_workers: number of workers to process in parallel\n",
        "\n",
        "    [saved]\n",
        "    * dictionary: numpy.ndarray of shape (K,F)\n",
        "    '''\n",
        "    # ----- TODO -----\n",
        "    list_of_args = []\n",
        "\n",
        "    n_clusters = 50\n",
        "\n",
        "\n",
        "    (X_train, y_train), (X_test, y_test) = mnist.load_data()\n",
        "    num_images = len(X_train)\n",
        "    datagen = ImageDataGenerator(featurewise_center=True,\n",
        "                             featurewise_std_normalization=True)\n",
        "\n",
        "    for i in range(num_images):\n",
        "        img = datagen.standardize(X_train[i])\n",
        "        operatedImage = np.float32(img) / 255\n",
        "        list_of_args.append([i, X_train[i]])\n",
        "\n",
        "    with multiprocessing.Pool(num_workers) as p:\n",
        "        p.map(compute_dictionary_one_image, list_of_args)\n",
        "\n",
        "    filter_responses = []\n",
        "    for file_name in os.listdir('./tmp'):\n",
        "        cur = np.load('./tmp/'+file_name)\n",
        "        if len(filter_responses) == 0:\n",
        "            filter_responses = cur\n",
        "        else:\n",
        "            filter_responses = np.vstack([filter_responses,cur])\n",
        "\n",
        "    kmeans = sklearn.cluster.KMeans(n_clusters=n_clusters).fit(filter_responses)\n",
        "    dictionary = kmeans.cluster_centers_ \n",
        "    np.save('dictionary.npy', dictionary)"
      ],
      "execution_count": 9,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "background_save": true,
          "base_uri": "https://localhost:8080/"
        },
        "id": "FT7JAxP5D7DX",
        "outputId": "63a0542c-a6da-4cde-b21d-d9830bc8e0c8"
      },
      "source": [
        "compute_dictionary()"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.7/dist-packages/keras_preprocessing/image/image_data_generator.py:720: UserWarning: This ImageDataGenerator specifies `featurewise_center`, but it hasn't been fit on any training data. Fit it first by calling `.fit(numpy_data)`.\n",
            "  warnings.warn('This ImageDataGenerator specifies '\n",
            "/usr/local/lib/python3.7/dist-packages/keras_preprocessing/image/image_data_generator.py:728: UserWarning: This ImageDataGenerator specifies `featurewise_std_normalization`, but it hasn't been fit on any training data. Fit it first by calling `.fit(numpy_data)`.\n",
            "  warnings.warn('This ImageDataGenerator specifies '\n"
          ]
        }
      ]
    }
  ]
}